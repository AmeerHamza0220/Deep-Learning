{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM5pkITweTiiZSGrsTT0Euu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/Deep-Learning/blob/main/CNNBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tHKpXQGTfnW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 32,32\n",
        "num_channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "KGrg4k9LWvfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(112,activation='relu',kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "5nDEBDrZUBsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "               metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [tf.keras.callbacks.TensorBoard('./keras')]\n",
        "model.fit(x_train, y_train, epochs=2, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks)"
      ],
      "metadata": {
        "id": "s8zARj-JUosp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic stuff using convulution and pooling"
      ],
      "metadata": {
        "id": "BJ7P45V9ZfmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/d/da/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg"
      ],
      "metadata": {
        "id": "7nP7ZiWQZe8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io        # Package to simply read images"
      ],
      "metadata": {
        "id": "QjlFj1HfZoH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('/content/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg').convert('L').resize((600,600))\n"
      ],
      "metadata": {
        "id": "I9CmyeCNZpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D-BIyZzwc6FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "eRZZQ6lxc638"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "5XvxzRG_Zu03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.img_to_array(image)"
      ],
      "metadata": {
        "id": "XmA4jKYhZ4vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.expand_dims(image, axis=0)\n",
        " #tensorflow work on batches "
      ],
      "metadata": {
        "id": "WCT1UERXZ_nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Tensor shape: {}\".format(image.shape))"
      ],
      "metadata": {
        "id": "IAXFCrAiaFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " we define a 3x3 filter (or kernel) commonly used to blur images (Gaussian blur):"
      ],
      "metadata": {
        "id": "QVk-L5mvbC9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[1 / 16, 2 / 16, 1 / 16],\n",
        "                      [2 / 16, 4 / 16, 2 / 16],\n",
        "                      [1 / 16, 2 / 16, 1 / 16]], tf.float32, name=\"gaussian_kernel\")"
      ],
      "metadata": {
        "id": "A_6AVz0ObF6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)\n",
        "kernel.shape"
      ],
      "metadata": {
        "id": "ZtKl-kHQbJF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")"
      ],
      "metadata": {
        "id": "NRRTgkElbQ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_res = blurred_image.numpy()\n",
        "# We \"unbatch\" our result by selecting the first (and only) image; we also remove the depth dimension:\n",
        "blurred_res = blurred_res[0, ..., 0]\n",
        "\n",
        "plt.imshow(blurred_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "m0mFMMDQbYlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a kernel for contour detection is used. This kernel is defined as follows:"
      ],
      "metadata": {
        "id": "z_JkplmncUXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[-1, -1, -1],\n",
        "                      [-1,  8, -1],\n",
        "                      [-1, -1, -1]], tf.float32, name=\"edge_kernel\")\n",
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)"
      ],
      "metadata": {
        "id": "sxvXHwvOcVyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_image = tf.nn.conv2d(image, kernel, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "edge_res = edge_image.numpy()[0, ..., 0]\n",
        "plt.imshow(edge_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "rJltIO6nca6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For max-pooling and average-pooling, the values in each window are aggregated into a single output, applying respectively the max or averaging operation. Once again, we use the low-level TensorFlow API to reproduce the results shown in the chapter:"
      ],
      "metadata": {
        "id": "DqBXmFGgcpP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pooled_image = tf.nn.avg_pool(image, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "avg_res = avg_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(avg_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "kQlWkw87cp8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pooled_image = tf.nn.max_pool(image, ksize=[1, 10, 10, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "max_res = max_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(max_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "zhbyW1rKeB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple convulutional network"
      ],
      "metadata": {
        "id": "k8VnnsjceUeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "    def __init__(self,num_classes):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1=tf.keras.layers.Conv2D(20,kernel_size=5,padding=\"same\",activation='relu')\n",
        "        self.conv2=tf.keras.layers.Conv2D(30,kernel_size=5,activation='relu')\n",
        "        self.maxpool=tf.keras.layers.MaxPooling2D(pool_size=2)\n",
        "        self.flatten=tf.keras.layers.Flatten()\n",
        "        self.dense1=tf.keras.layers.Dense(400,activation='relu')\n",
        "        self.dense2=tf.keras.layers.Dense(num_classes,activation='relu')\n",
        "    def call(self,input):\n",
        "        x=self.conv1(input)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.conv2(x)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.flatten(x)\n",
        "        x=self.dense1(x)\n",
        "        x=self.dense2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mrScGKh_fDkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 32,32\n",
        "num_channels = 3"
      ],
      "metadata": {
        "id": "BTbLjyjPq_TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "class LeNet5(Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        :param num_classes:     Number of classes to predict from\n",
        "        \"\"\"\n",
        "        super(LeNet5, self).__init__()\n",
        "        # We instantiate the various layers composing LeNet-5:\n",
        "        # self.conv1 = SimpleConvolutionLayer(6, kernel_size=(5, 5))\n",
        "        # self.conv2 = SimpleConvolutionLayer(16, kernel_size=(5, 5))\n",
        "        # ... or using the existing and (recommended) Conv2D class:\n",
        "        self.conv1 = Conv2D(6, 5, padding='same', activation='relu')\n",
        "        self.conv2 = Conv2D(16, 5, activation='relu')\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu')\n",
        "        self.dense2 = Dense(84, activation='relu')\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layers and perform their operations on the input tensors\n",
        "        :param inputs:  Input tensor\n",
        "        :return:        Output tensor\n",
        "        \"\"\"\n",
        "        x = self.max_pool(self.conv1(inputs))        # 1st block\n",
        "        x = self.max_pool(self.conv2(x))             # 2nd block\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x))) # dense layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "C4mwLn-dh6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "\n",
        "\n",
        "model = LeNet5(10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]\n",
        "# batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "# model.build(input_shape=batched_input_shape)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "qkflUo1eexlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32, epochs=10, validation_data=(x_test, y_test), \n",
        "                    verbose=1,  # change to `verbose=1` to get a progress bar\n",
        "                                # (we opt for `verbose=2` here to reduce the log size)\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "Z2o6UijJgKaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "aMhiVileeUEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "aeJFM8Qge9W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improving above lenet with batchnorm and l1 regularization"
      ],
      "metadata": {
        "id": "5cHCEiY9xUJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "class LeNet(Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        :param num_classes:     Number of classes to predict from\n",
        "        \"\"\"\n",
        "        super(LeNet, self).__init__()\n",
        "        # We instantiate the various layers composing LeNet-5:\n",
        "        # self.conv1 = SimpleConvolutionLayer(6, kernel_size=(5, 5))\n",
        "        # self.conv2 = SimpleConvolutionLayer(16, kernel_size=(5, 5))\n",
        "        # ... or using the existing and (recommended) Conv2D class:\n",
        "        self.conv1 = Conv2D(6, 5, padding='same', activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.bn1=tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = Conv2D(16, 5, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.bn2=tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.dense2 = Dense(84, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layers and perform their operations on the input tensors\n",
        "        :param inputs:  Input tensor\n",
        "        :return:        Output tensor\n",
        "        \"\"\"\n",
        "        x = self.max_pool(self.conv1(inputs))        # 1st block\n",
        "        x = self.max_pool(self.conv2(x))             # 2nd block\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x))) # dense layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "DqFyIZWSv9wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "\n",
        "\n",
        "model = LeNet(10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]\n",
        "# batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "# model.build(input_shape=batched_input_shape)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "1zNS78h7yGFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32, epochs=10, validation_data=(x_test, y_test), \n",
        "                    verbose=1,  # change to `verbose=1` to get a progress bar\n",
        "                                # (we opt for `verbose=2` here to reduce the log size)\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "c9jF-ZEcyI8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will implement Resnet"
      ],
      "metadata": {
        "id": "k6gbwY280GqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvWithBatchNorm(tf.keras.layers.Conv2D):\n",
        "    # This is a custom layer that wraps a Conv2D layer with BatchNormalization and a ReLU activation\n",
        "    def __init__(self,activation='relu', name='convbn',**kwargs):\n",
        "        \"\"\"\n",
        "        :param activation: activation function to use\n",
        "        :param name: name of the layer\n",
        "        :param kwargs: arguments for the Conv2D layer\n",
        "        \"\"\"\n",
        "        self.activation=tf.keras.layers.Activation(activation,name=name) if \\\n",
        "                          activation is not None else None\n",
        "        super().__init__(activation=None, name=name + '_c', **kwargs)\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(axis=-1, name=name + '_bn')\n",
        "    def call(self,input,training=None):\n",
        "        x = super().call(inputs) #conv2d\n",
        "        x=self.batch_norm(x,training=training)\n",
        "        if self.activation is not None:\n",
        "            x=self.activation(x)\n",
        "        return x\n",
        "\n",
        "import functools\n",
        "\n",
        "class ResidualMerge(tf.keras.layers.Layer):\n",
        "    \"\"\" Layer to merge the original tensor and the residual one in residual blocks\"\"\"\n",
        "\n",
        "    def __init__(self, name='block', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the layer. \n",
        "        :param activation:   Activation function (name or callable)\n",
        "        :param name:         Name suffix for the sub-layers.\n",
        "        :param kwargs:       Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__(name=name)\n",
        "        self.shortcut = None\n",
        "        self.kwargs = kwargs\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        x_shape = input_shape[0]\n",
        "        x_residual_shape = input_shape[1]\n",
        "        if x_shape[1] == x_residual_shape[1] and \\\n",
        "           x_shape[2] == x_residual_shape[2] and \\\n",
        "           x_shape[3] == x_residual_shape[3]:\n",
        "            self.shortcut = functools.partial(tf.identity, name=self.name + '_shortcut')\n",
        "        else:\n",
        "            strides = (\n",
        "                int(round(x_shape[1] / x_residual_shape[1])), # vertical stride\n",
        "                int(round(x_shape[2] / x_residual_shape[2]))  # horizontal stride\n",
        "            )\n",
        "            x_residual_channels = x_residual_shape[3]\n",
        "            self.shortcut = ConvWithBatchNorm(\n",
        "                filters=x_residual_channels, kernel_size=(1, 1), strides=strides,\n",
        "                activation=None, name=self.name + '_shortcut_c', **self.kwargs)\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layer. \n",
        "        :param inputs:         Tuple of two input tensors to merge\n",
        "        :return:               Merged tensor\n",
        "        \"\"\"\n",
        "        x, x_residual = inputs\n",
        "        \n",
        "        x_shortcut = self.shortcut(x)\n",
        "        x_merge = tf.add([x_shortcut, x_residual])\n",
        "        return x_merge\n",
        "\n",
        "class BasicResidualBlock(tf.keras.Model):\n",
        "    # This is a basic residual block with two convolutional layers and a residual merge\n",
        "    def __init__(self, filter=16,kernal_size=1,strides=1,activation='relu',kernel_initializer ='he_normal',kernel_regularizer=tf.keras.regularizers.l2(1e-4),name='block_basic',**kwargs):\n",
        "        \"\"\"\n",
        "        :param filter:         Number of filters in the convolutional layers\n",
        "        :param kernal_size:    Size of the convolutional kernels\n",
        "        :param strides:        Stride of the convolutional layers\n",
        "        :param activation:     Activation function (name or callable)\n",
        "        :param kernel_initializer : Initializer for the convolutional kernels\n",
        "        :param kernel_regularizer: Regularizer for the convolutional kernels\n",
        "        :param name:           Name suffix for the sub-layers.\n",
        "        :param kwargs:         Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        self.conv1 = ConvWithBatchNorm(\n",
        "            filters=filter, kernel_size=kernal_size, strides=strides,\n",
        "            activation=activation, \n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_c1', **kwargs)\n",
        "        self.conv2 = ConvWithBatchNorm(\n",
        "            filters=filter, kernel_size=kernal_size, strides=strides,\n",
        "            activation=activation,\n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            kernel_regularizer=kernel_regularizer, name=name + '_c2', **kwargs)\n",
        "        self.merge = ResidualMerge(name=name + '_merge',kernel_initializer =kernel_initializer ,kernel_regularizer=kernel_regularizer)\n",
        "        self.activation = tf.keras.layers.Activation(activation,name=name + '_activation')\n",
        "    def call(self,inputs,training=None):\n",
        "        x = self.conv1(inputs,training=training)\n",
        "        x = self.conv2(x,training=training)\n",
        "        x = self.merge([inputs, x])\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlockWithBottleneck(tf.keras.Model):\n",
        "    # This is a residual block with a bottleneck layer\n",
        "    def __init__(self, filter=16,kernal_size=1,strides=1,activation='relu',kernel_initializer ='he_normal',kernel_regularizer=tf.keras.regularizers.l2(1e-4),name='block_bottleneck',**kwargs):\n",
        "        \"\"\"\n",
        "        :param filter:         Number of filters in the convolutional layers\n",
        "        :param kernal_size:    Size of the convolutional kernels\n",
        "        :param strides:        Stride of the convolutional layers\n",
        "        :param activation:     Activation function (name or callable)\n",
        "        :param kernel_initializer : Initializer for the convolutional kernels\n",
        "        :param kernel_regularizer: Regularizer for the convolutional kernels\n",
        "        :param name:           Name suffix for the sub-layers.\n",
        "        :param kwargs:         Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        self.conv1 = ConvWithBatchNorm(\n",
        "            filters=filter, kernel_size=kernal_size, strides=strides,\n",
        "            activation=activation, \n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_c1', **kwargs)\n",
        "        self.conv2 = ConvWithBatchNorm(\n",
        "            filters=filter, kernel_size=kernal_size, strides=strides,\n",
        "            activation=activation,\n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            kernel_regularizer=kernel_regularizer, name=name + '_c2', **kwargs)\n",
        "        self.conv3 = ConvWithBatchNorm(\n",
        "            filters=filter*4, kernel_size=1, strides=1,\n",
        "            activation=activation,\n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            kernel_regularizer=kernel_regularizer, name=name + '_c3', **kwargs)\n",
        "        self.merge = ResidualMerge(name=name + '_merge',kernel_initializer =kernel_initializer ,kernel_regularizer=kernel_regularizer)\n",
        "        self.activation = tf.keras.layers.Activation(activation,name=name + '_activation')\n",
        "        \n",
        "    def call(self,inputs,training=None):\n",
        "        x = self.conv1(inputs,training=training)\n",
        "        x = self.conv2(x,training=training)\n",
        "        x = self.conv3(x,training=training)\n",
        "        x = self.merge([inputs, x])\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MacroResidualBlock(tf.keras.models.Sequential):\n",
        "    #multiple residual blocks as sequential model\n",
        "    def __init__(self, block_class=ResidualBlockWithBottleneck,repititions=3,filter=16,kernal_size=1,strides=1,activation='relu',kernel_initializer ='he_normal',kernel_regularizer=tf.keras.regularizers.l2(1e-4),name='block_macro',**kwargs):\n",
        "        \n",
        "        super.__init__([block_class(filter=filter,kernal_size=kernal_size,strides=strides,activation=activation,kernel_initializer =kernel_initializer ,kernel_regularizer=kernel_regularizer,name=name+'_block_'+str(i),**kwargs) for i in range(repititions)],name=name)\n",
        "\n",
        "class ResNet(tf.keras.Sequential):\n",
        "    # ResNet model\n",
        "    def __init__(self, input_shape,num_classes=1000,block_class=ResidualBlockWithBottleneck,repititions=3,activation='relu',kernel_initializer ='he_normal',kernel_regularizer=tf.keras.regularizers.l2(1e-4),name='resnet',**kwargs):\n",
        "        \"\"\"\n",
        "        :param input_shape:     Shape of the input image\n",
        "        :param num_classes:     Number of classes in the dataset\n",
        "        :param block_class:     Class of the residual block\n",
        "        :param repititions:     Number of residual blocks\n",
        "        :param activation:      Activation function (name or callable)\n",
        "        :param kernel_initializer : Initializer for the convolutional kernels\n",
        "        :param kernel_regularizer: Regularizer for the convolutional kernels\n",
        "        :param name:            Name suffix for the sub-layers.\n",
        "        :param kwargs:          Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        filter=64\n",
        "        strides=2\n",
        "        super.__init__(\n",
        "           #initial conv and pool layer\n",
        "               [tf.keras.layers.Input(shape=input_shape),\n",
        "              ConvWithBatchNorm(\n",
        "                    filters=filter, kernel_size=7, strides=2,\n",
        "                    activation='relu',\n",
        "                    kernel_initializer =kernel_initializer ,\n",
        "                    kernel_regularizer=kernel_regularizer,\n",
        "                    padding='same',\n",
        "                    name='conv'),\n",
        "                tf.keras.layers.MaxPool2D(pool_size=3, strides=strides, \n",
        "                padding='same')]+\n",
        "            #residual blocks\n",
        "            [block_class(filter=min(filters * (2 ** i), 1024),kernal_size=kernal_size,strides=strides if i !=0 else 1,activation=activation,kernel_initializer =kernel_initializer ,kernel_regularizer=kernel_regularizer,name=name+'_block_'+str(i),**kwargs) for i in range(repititions)]+\n",
        "            #final classification layer\n",
        "            [tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Dense(num_classes,\n",
        "            kernel_initializer =kernel_initializer ,\n",
        "            activation='softmax',\n",
        "            name='classification')])\n"
      ],
      "metadata": {
        "id": "AFuaWf8g0JBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet18',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=BasicResidualBlock, repetitions=(2, 2, 2, 2),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "        \n",
        "class ResNet34(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet34',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=BasicResidualBlock, repetitions=(3, 4, 6, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "        \n",
        "class ResNet50(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet50',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 4, 6, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "class ResNet101(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet101',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 4, 23, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "class ResNet152(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet152',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 8, 36, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)"
      ],
      "metadata": {
        "id": "x_gbLetREhh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [224, 224, 3] \n",
        "num_classes=1000\n",
        "model = ResNet50(input_shape, num_classes)\n",
        "model.summary(line_length=80, positions=[.5, .85, 1.])"
      ],
      "metadata": {
        "id": "HiR143bHFWQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}