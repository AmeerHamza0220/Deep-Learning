{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNJVykuArI7773C0qHovIDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/Deep-Learning/blob/main/CNNBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tHKpXQGTfnW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 32,32\n",
        "num_channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "KGrg4k9LWvfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(112,activation='relu',kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "5nDEBDrZUBsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "               metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [tf.keras.callbacks.TensorBoard('./keras')]\n",
        "model.fit(x_train, y_train, epochs=2, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks)"
      ],
      "metadata": {
        "id": "s8zARj-JUosp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic stuff using convulution and pooling"
      ],
      "metadata": {
        "id": "BJ7P45V9ZfmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/d/da/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg"
      ],
      "metadata": {
        "id": "7nP7ZiWQZe8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io        # Package to simply read images"
      ],
      "metadata": {
        "id": "QjlFj1HfZoH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('/content/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg').convert('L').resize((600,600))\n"
      ],
      "metadata": {
        "id": "I9CmyeCNZpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D-BIyZzwc6FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "eRZZQ6lxc638"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "5XvxzRG_Zu03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.img_to_array(image)"
      ],
      "metadata": {
        "id": "XmA4jKYhZ4vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.expand_dims(image, axis=0)\n",
        " #tensorflow work on batches "
      ],
      "metadata": {
        "id": "WCT1UERXZ_nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Tensor shape: {}\".format(image.shape))"
      ],
      "metadata": {
        "id": "IAXFCrAiaFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " we define a 3x3 filter (or kernel) commonly used to blur images (Gaussian blur):"
      ],
      "metadata": {
        "id": "QVk-L5mvbC9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[1 / 16, 2 / 16, 1 / 16],\n",
        "                      [2 / 16, 4 / 16, 2 / 16],\n",
        "                      [1 / 16, 2 / 16, 1 / 16]], tf.float32, name=\"gaussian_kernel\")"
      ],
      "metadata": {
        "id": "A_6AVz0ObF6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)\n",
        "kernel.shape"
      ],
      "metadata": {
        "id": "ZtKl-kHQbJF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")"
      ],
      "metadata": {
        "id": "NRRTgkElbQ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_res = blurred_image.numpy()\n",
        "# We \"unbatch\" our result by selecting the first (and only) image; we also remove the depth dimension:\n",
        "blurred_res = blurred_res[0, ..., 0]\n",
        "\n",
        "plt.imshow(blurred_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "m0mFMMDQbYlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a kernel for contour detection is used. This kernel is defined as follows:"
      ],
      "metadata": {
        "id": "z_JkplmncUXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[-1, -1, -1],\n",
        "                      [-1,  8, -1],\n",
        "                      [-1, -1, -1]], tf.float32, name=\"edge_kernel\")\n",
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)"
      ],
      "metadata": {
        "id": "sxvXHwvOcVyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_image = tf.nn.conv2d(image, kernel, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "edge_res = edge_image.numpy()[0, ..., 0]\n",
        "plt.imshow(edge_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "rJltIO6nca6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For max-pooling and average-pooling, the values in each window are aggregated into a single output, applying respectively the max or averaging operation. Once again, we use the low-level TensorFlow API to reproduce the results shown in the chapter:"
      ],
      "metadata": {
        "id": "DqBXmFGgcpP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pooled_image = tf.nn.avg_pool(image, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "avg_res = avg_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(avg_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "kQlWkw87cp8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pooled_image = tf.nn.max_pool(image, ksize=[1, 10, 10, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "max_res = max_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(max_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "zhbyW1rKeB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple convulutional network"
      ],
      "metadata": {
        "id": "k8VnnsjceUeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "    def __init__(self,num_classes):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1=tf.keras.layers.Conv2D(20,kernel_size=5,padding=\"same\",activation='relu')\n",
        "        self.conv2=tf.keras.layers.Conv2D(30,kernel_size=5,activation='relu')\n",
        "        self.maxpool=tf.keras.layers.MaxPooling2D(pool_size=2)\n",
        "        self.flatten=tf.keras.layers.Flatten()\n",
        "        self.dense1=tf.keras.layers.Dense(400,activation='relu')\n",
        "        self.dense2=tf.keras.layers.Dense(num_classes,activation='relu')\n",
        "    def call(self,input):\n",
        "        x=self.conv1(input)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.conv2(x)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.flatten(x)\n",
        "        x=self.dense1(x)\n",
        "        x=self.dense2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mrScGKh_fDkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 32,32\n",
        "num_channels = 3"
      ],
      "metadata": {
        "id": "BTbLjyjPq_TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "class LeNet5(Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        :param num_classes:     Number of classes to predict from\n",
        "        \"\"\"\n",
        "        super(LeNet5, self).__init__()\n",
        "        # We instantiate the various layers composing LeNet-5:\n",
        "        # self.conv1 = SimpleConvolutionLayer(6, kernel_size=(5, 5))\n",
        "        # self.conv2 = SimpleConvolutionLayer(16, kernel_size=(5, 5))\n",
        "        # ... or using the existing and (recommended) Conv2D class:\n",
        "        self.conv1 = Conv2D(6, 5, padding='same', activation='relu')\n",
        "        self.conv2 = Conv2D(16, 5, activation='relu')\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu')\n",
        "        self.dense2 = Dense(84, activation='relu')\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layers and perform their operations on the input tensors\n",
        "        :param inputs:  Input tensor\n",
        "        :return:        Output tensor\n",
        "        \"\"\"\n",
        "        x = self.max_pool(self.conv1(inputs))        # 1st block\n",
        "        x = self.max_pool(self.conv2(x))             # 2nd block\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x))) # dense layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "C4mwLn-dh6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "\n",
        "\n",
        "model = LeNet5(10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]\n",
        "# batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "# model.build(input_shape=batched_input_shape)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "qkflUo1eexlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32, epochs=10, validation_data=(x_test, y_test), \n",
        "                    verbose=1,  # change to `verbose=1` to get a progress bar\n",
        "                                # (we opt for `verbose=2` here to reduce the log size)\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "Z2o6UijJgKaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "aMhiVileeUEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "aeJFM8Qge9W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improving above lenet with batchnorm and l1 regularization"
      ],
      "metadata": {
        "id": "5cHCEiY9xUJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "class LeNet(Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        :param num_classes:     Number of classes to predict from\n",
        "        \"\"\"\n",
        "        super(LeNet, self).__init__()\n",
        "        # We instantiate the various layers composing LeNet-5:\n",
        "        # self.conv1 = SimpleConvolutionLayer(6, kernel_size=(5, 5))\n",
        "        # self.conv2 = SimpleConvolutionLayer(16, kernel_size=(5, 5))\n",
        "        # ... or using the existing and (recommended) Conv2D class:\n",
        "        self.conv1 = Conv2D(6, 5, padding='same', activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.bn1=tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = Conv2D(16, 5, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.bn2=tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.dense2 = Dense(84, activation='relu',   kernel_regularizer=tf.keras.regularizers.l1(0.01),)\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layers and perform their operations on the input tensors\n",
        "        :param inputs:  Input tensor\n",
        "        :return:        Output tensor\n",
        "        \"\"\"\n",
        "        x = self.max_pool(self.conv1(inputs))        # 1st block\n",
        "        x = self.max_pool(self.conv2(x))             # 2nd block\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x))) # dense layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "DqFyIZWSv9wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "\n",
        "\n",
        "model = LeNet(10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]\n",
        "# batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "# model.build(input_shape=batched_input_shape)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "1zNS78h7yGFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32, epochs=10, validation_data=(x_test, y_test), \n",
        "                    verbose=1,  # change to `verbose=1` to get a progress bar\n",
        "                                # (we opt for `verbose=2` here to reduce the log size)\n",
        "                    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "id": "c9jF-ZEcyI8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will implement Resnet"
      ],
      "metadata": {
        "id": "k6gbwY280GqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Activation, Dense, Flatten, Conv2D, MaxPooling2D, \n",
        "    GlobalAveragePooling2D, AveragePooling2D, BatchNormalization, add)\n",
        "import tensorflow.keras.regularizers as regulizers\n",
        "import functools\n",
        "\n",
        "class ConvWithBatchNorm(tf.keras.layers.Conv2D):\n",
        "    \"\"\" Convolutional layer with batch normalization\"\"\"\n",
        "\n",
        "    def __init__(self, activation='relu', name='convbn', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the layer. \n",
        "        :param activation:   Activation function (name or callable)\n",
        "        :param name:         Name suffix for the sub-layers.\n",
        "        :param kwargs:       Mandatory and optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        \n",
        "        self.activation = Activation(\n",
        "            activation, name=name + '_act') if activation is not None else None\n",
        "        \n",
        "        super().__init__(activation=None, name=name + '_c', **kwargs)\n",
        "        \n",
        "        self.batch_norm = BatchNormalization(axis=-1, name=name + '_bn')\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Call the layer. \n",
        "        :param inputs:         Input tensor to process\n",
        "        :param training:       Flag to let TF knows if it is a training iteration or not\n",
        "                               (this will affect the behavior of BatchNorm)\n",
        "        :return:               Convolved tensor\n",
        "        \"\"\"\n",
        "        x = super().call(inputs)\n",
        "        x = self.batch_norm(x, training=training)\n",
        "        if self.activation is not None:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResidualMerge(tf.keras.layers.Layer):\n",
        "    \"\"\" Layer to merge the original tensor and the residual one in residual blocks\"\"\"\n",
        "\n",
        "    def __init__(self, name='block', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the layer. \n",
        "        :param activation:   Activation function (name or callable)\n",
        "        :param name:         Name suffix for the sub-layers.\n",
        "        :param kwargs:       Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__(name=name)\n",
        "        self.shortcut = None\n",
        "        self.kwargs = kwargs\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        x_shape = input_shape[0]\n",
        "        x_residual_shape = input_shape[1]\n",
        "        if x_shape[1] == x_residual_shape[1] and \\\n",
        "           x_shape[2] == x_residual_shape[2] and \\\n",
        "           x_shape[3] == x_residual_shape[3]:\n",
        "            self.shortcut = functools.partial(tf.identity, name=self.name + '_shortcut')\n",
        "        else:\n",
        "            strides = (\n",
        "                int(round(x_shape[1] / x_residual_shape[1])), # vertical stride\n",
        "                int(round(x_shape[2] / x_residual_shape[2]))  # horizontal stride\n",
        "            )\n",
        "            x_residual_channels = x_residual_shape[3]\n",
        "            self.shortcut = ConvWithBatchNorm(\n",
        "                filters=x_residual_channels, kernel_size=(1, 1), strides=strides,\n",
        "                activation=None, name=self.name + '_shortcut_c', **self.kwargs)\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layer. \n",
        "        :param inputs:         Tuple of two input tensors to merge\n",
        "        :return:               Merged tensor\n",
        "        \"\"\"\n",
        "        x, x_residual = inputs\n",
        "        \n",
        "        x_shortcut = self.shortcut(x)\n",
        "        x_merge = add([x_shortcut, x_residual])\n",
        "        return x_merge\n",
        "\n",
        "class BasicResidualBlock(tf.keras.Model):\n",
        "    \"\"\" Basic residual block\"\"\"\n",
        "\n",
        "    def __init__(self, filters=16, kernel_size=1, strides=1, activation='relu',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4),\n",
        "                 name='res_basic', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the layer. \n",
        "        :param filters:                 Number of filters\n",
        "        :param kernel_size:             Kernel size\n",
        "        :param strides:                 Convolution strides\n",
        "        :param activation:              Activation function (name or callable)\n",
        "        :param kernel_initializer:      Kernel initialisation method name\n",
        "        :param kernel_regularizer:      Kernel regularizer\n",
        "        :param name:                    Name suffix for the sub-layers.\n",
        "        :param kwargs:                  Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        self.conv_1 = ConvWithBatchNorm(\n",
        "            filters=filters, kernel_size=kernel_size, activation=activation, padding='same',\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            strides=strides, name=name + '_cb_1', **kwargs)\n",
        "        \n",
        "        self.conv_2 = ConvWithBatchNorm(\n",
        "            filters=filters, kernel_size=kernel_size, activation=None, padding='same',\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            strides=1, name=name + '_cb_2', **kwargs)\n",
        "        \n",
        "        self.merge = ResidualMerge(\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, \n",
        "            name=name)\n",
        "        \n",
        "        self.activation = Activation(activation, name=name + '_act')\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Call the block. \n",
        "        :param inputs:         Input tensor to process\n",
        "        :param training:       Flag to let TF knows if it is a training iteration or not\n",
        "                               (this will affect the behavior of BatchNorm)\n",
        "        :return:               Block output tensor\n",
        "        \"\"\"\n",
        "        x = inputs\n",
        "        # Residual path:\n",
        "        x_residual = self.conv_1(x, training=training)\n",
        "        x_residual = self.conv_2(x_residual, training=training)\n",
        "        \n",
        "        # Merge residual result with original tensor:\n",
        "        x_merge = self.merge([x, x_residual])\n",
        "        x_merge = self.activation(x_merge)\n",
        "        return x_merge\n",
        "\n",
        "class ResidualBlockWithBottleneck(tf.keras.Model):\n",
        "    \"\"\" Residual block with bottleneck, recommended for deep ResNets (depth > 34)\"\"\"\n",
        "    def __init__(self, filters=16, kernel_size=1, strides=1, activation='relu',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4),\n",
        "                 name='res_basic', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the block. \n",
        "        :param filters:                 Number of filters\n",
        "        :param kernel_size:             Kernel size\n",
        "        :param strides:                 Convolution strides\n",
        "        :param activation:              Activation function (name or callable)\n",
        "        :param kernel_initializer:      Kernel initialisation method name\n",
        "        :param kernel_regularizer:      Kernel regularizer\n",
        "        :param name:                    Name suffix for the sub-layers.\n",
        "        :param kwargs:                  Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        self.conv_0 = ConvWithBatchNorm(\n",
        "            filters=filters, kernel_size=1, activation=activation, padding='valid',\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            strides=1, name=name + '_cb_0', **kwargs)\n",
        "        \n",
        "        self.conv_1 = ConvWithBatchNorm(\n",
        "            filters=filters, kernel_size=kernel_size, activation=activation, padding='same',\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            strides=strides, name=name + '_cb_1', **kwargs)\n",
        "        \n",
        "        self.conv_2 = ConvWithBatchNorm(\n",
        "            filters=4 * filters, kernel_size=1, activation=None, padding='valid',\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            strides=1, name=name + '_cb_2', **kwargs)\n",
        "        \n",
        "        self.merge = ResidualMerge(\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, \n",
        "            name=name)\n",
        "        \n",
        "        self.activation = Activation(activation, name=name + '_act')\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Call the layer. \n",
        "        :param inputs:         Input tensor to process\n",
        "        :param training:       Flag to let TF knows if it is a training iteration or not\n",
        "                               (this will affect the behavior of BatchNorm)\n",
        "        :return:               Block output tensor\n",
        "        \"\"\"\n",
        "        x = inputs\n",
        "        # Residual path:\n",
        "        x_residual = self.conv_0(x, training=training)\n",
        "        x_residual = self.conv_1(x_residual, training=training)\n",
        "        x_residual = self.conv_2(x_residual, training=training)\n",
        "        \n",
        "        # Merge residual result with original tensor:\n",
        "        x_merge = self.merge([x, x_residual])\n",
        "        x_merge = self.activation(x_merge)\n",
        "        return x_merge\n",
        "\n",
        "class ResidualMacroBlock(tf.keras.models.Sequential):\n",
        "    \"\"\" Macro-block, chaining multiple residual blocks (as a Sequential model)\"\"\"\n",
        "\n",
        "    def __init__(self, block_class=ResidualBlockWithBottleneck, repetitions=3, \n",
        "                 filters=16, kernel_size=1, strides=1, activation='relu',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4),\n",
        "                 name='res_macroblock', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the block. \n",
        "        :param block_class:             Block class to be used.\n",
        "        :param repetitions:             Number of times the block should be repeated inside.\n",
        "        :param filters:                 Number of filters\n",
        "        :param kernel_size:             Kernel size\n",
        "        :param strides:                 Convolution strides\n",
        "        :param activation:              Activation function (name or callable)\n",
        "        :param kernel_initializer:      Kernel initialisation method name\n",
        "        :param kernel_regularizer:      Kernel regularizer\n",
        "        :param name:                    Name suffix for the sub-layers.\n",
        "        :param kwargs:                  Optional parameters of tf.keras.layers.Conv2D\n",
        "        \"\"\"\n",
        "        super().__init__(\n",
        "            [block_class(\n",
        "                 filters=filters, kernel_size=kernel_size, activation=activation,\n",
        "                 strides=strides if i == 0 else 1, name=\"{}_{}\".format(name, i),\n",
        "                 kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "             for i in range(repetitions)], \n",
        "            name=name)\n",
        "        \n",
        "class ResNet(tf.keras.models.Sequential):\n",
        "    \"\"\" ResNet model for classification\"\"\"\n",
        "\n",
        "    def __init__(self, input_shape, num_classes=1000, \n",
        "                 block_class=ResidualBlockWithBottleneck, repetitions=(2, 2, 2, 2),\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4),\n",
        "                 name='resnet'):\n",
        "        \"\"\"\n",
        "        Initialize a ResNet model for classification.\n",
        "        :param input_shape:             Input shape (e.g. (224, 224, 3))\n",
        "        :param num_classes:             Number of classes to predict\n",
        "        :param block_class:             Block class to be used\n",
        "        :param repetitions:             List of repetitions for each macro-blocks the network should contain\n",
        "        :param kernel_initializer:      Kernel initialisation method name\n",
        "        :param kernel_regularizer:      Kernel regularizer\n",
        "        :param name:                    Model's name\n",
        "        :return:                        ResNet model.\n",
        "        \"\"\"\n",
        "    \n",
        "        filters = 64\n",
        "        strides = 2\n",
        "    \n",
        "        super().__init__(\n",
        "            # Initial conv + max-pool layers:\n",
        "            [Input(shape=input_shape, name='input'),\n",
        "             ConvWithBatchNorm(\n",
        "                 filters=filters, kernel_size=7, activation='relu', padding='same', strides=strides,\n",
        "                 kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "                 name='conv'),\n",
        "             MaxPooling2D(pool_size=3, strides=strides, padding='same', name='max_pool')\n",
        "            ] + \\\n",
        "            # Residual blocks:\n",
        "            [ResidualMacroBlock(\n",
        "                 block_class=block_class, repetitions=repet, \n",
        "                 filters=min(filters * (2 ** i), 1024), kernel_size=3, activation='relu',\n",
        "                 strides=strides if i != 0 else 1, name='block_{}'.format(i),\n",
        "                 kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "             for i, repet in enumerate(repetitions)\n",
        "            ] + \\\n",
        "            # Final layers leading to classification output:\n",
        "            [GlobalAveragePooling2D(name='avg_pool'),\n",
        "             Dense(units=num_classes, kernel_initializer=kernel_initializer, activation='softmax')\n",
        "            ], name=name)\n"
      ],
      "metadata": {
        "id": "AFuaWf8g0JBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ISGJ3jeWeRUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet18',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=BasicResidualBlock, repetitions=(2, 2, 2, 2),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "        \n",
        "class ResNet34(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet34',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=BasicResidualBlock, repetitions=(3, 4, 6, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "        \n",
        "class ResNet50(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet50',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 4, 6, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "class ResNet101(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet101',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 4, 23, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "class ResNet152(ResNet):\n",
        "    def __init__(self, input_shape, num_classes=1000, name='resnet152',\n",
        "                 kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(1e-4)):\n",
        "        super().__init__(input_shape, num_classes, \n",
        "                         block_class=ResidualBlockWithBottleneck, repetitions=(3, 8, 36, 3),\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)"
      ],
      "metadata": {
        "id": "x_gbLetREhh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [32, 32, 3] \n",
        "num_classes=10\n",
        "model = ResNet50(input_shape, num_classes)\n",
        "model.summary(line_length=80, positions=[.5, .85, 1.])"
      ],
      "metadata": {
        "id": "HiR143bHFWQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam() #tf.keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
        "\n",
        "accuracy_metric = tf.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "top5_accuracy_metric = tf.metrics.SparseTopKCategoricalAccuracy(k=5, name='top5_acc')\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n",
        "                 metrics=[accuracy_metric, top5_accuracy_metric])"
      ],
      "metadata": {
        "id": "uJPRW-7RgekB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,  \n",
        "                       epochs=10,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "RrlNObBzgk4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfor learning vision tranformer"
      ],
      "metadata": {
        "id": "NWur6cX9kKxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "qaDYUheOkkme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "ob6JtPsIk_mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "\n",
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n"
      ],
      "metadata": {
        "id": "HdUGf_Vtkpo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q flowers-recognition.zip\n",
        "!rm flowers-recognition.zip"
      ],
      "metadata": {
        "id": "5azaW2mYlO0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 5\n",
        "\n",
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/flowers\", labels='inferred',shuffle=True,image_size=(img_height,\n",
        "    img_width),subset=\"training\",\n",
        " validation_split=0.2,seed=123,\n",
        " batch_size=32\n",
        "\n",
        ")\n",
        "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/flowers\", labels='inferred',shuffle=True,image_size=(img_height,\n",
        "    img_width),subset=\"validation\",\n",
        " validation_split=0.2,seed=123,\n",
        " batch_size=32\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "8wBR-RmUlRgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "url=\"https://tfhub.dev/sayakpaul/vit_b8_fe/1\"\n",
        "hub_feature_extractor = hub.KerasLayer(\n",
        "    url, \n",
        "    trainable=False,                              # Flag to set the layers as trainable or not\n",
        "    input_shape=(224,224,3),   # Expected input shape.\n",
        "    output_shape=1000, # Output shape [batch_size, 2048].\n",
        "    dtype=tf.float32)    "
      ],
      "metadata": {
        "id": "4J4-FnKckN_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7TSf5fGYnUPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential(\n",
        "    [hub_feature_extractor,\n",
        "     tf.keras.layers.Dense(num_classes,activation='softmax')\n",
        "     \n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xmPZ3nhQmVk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top5_acc')\n",
        "    ])"
      ],
      "metadata": {
        "id": "8a6WEui_oWjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds,  epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "BjjtkJA2oegf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def load_image(image_path, size):\n",
        "    \"\"\"\n",
        "    Load an image as a Numpy array.\n",
        "    :param image_path:  Path of the image\n",
        "    :param size:        Target size\n",
        "    :return             Image array, normalized between 0 and 1\n",
        "    \"\"\"\n",
        "    image = img_to_array(load_img(image_path, target_size=size)) / 255.\n",
        "    return image\n",
        "\n",
        "\n",
        "def process_predictions(class_probabilities, class_readable_labels, k=5):\n",
        "    \"\"\"\n",
        "    Process a batch of predictions from our estimator.\n",
        "    :param class_probabilities:     Prediction results returned by the Keras classifier for a batch of data\n",
        "    :param class_readable_labels:   List of readable-class labels, for display\n",
        "    :param k:                       Number of top predictions to consider\n",
        "    :return                         Readable labels and probabilities for the predicted classes\n",
        "    \"\"\"\n",
        "    topk_labels, topk_probabilities = [], []\n",
        "    for i in range(len(class_probabilities)):\n",
        "        # Getting the top-k predictions:\n",
        "        topk_classes = sorted(np.argpartition(class_probabilities[i], -k)[-k:])\n",
        "    \n",
        "        # Getting the corresponding labels and probabilities:\n",
        "        topk_labels.append([class_readable_labels[predicted] for predicted in topk_classes])\n",
        "        topk_probabilities.append(class_probabilities[i][topk_classes])\n",
        "    \n",
        "    return topk_labels, topk_probabilities\n",
        "\n",
        "\n",
        "def display_predictions(images, topk_labels, topk_probabilities):\n",
        "    \"\"\"\n",
        "    Plot a batch of predictions.\n",
        "    :param images:                  Batch of input images\n",
        "    :param topk_labels:             String labels of predicted classes\n",
        "    :param topk_probabilities:      Probabilities for each class\n",
        "    \"\"\"\n",
        "    num_images = len(images)\n",
        "    num_images_sqrt = np.sqrt(num_images)\n",
        "    plot_cols = plot_rows = int(np.ceil(num_images_sqrt))\n",
        "    \n",
        "    figure = plt.figure(figsize=(13,10))\n",
        "    grid_spec = gridspec.GridSpec(plot_cols, plot_rows)\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        img, pred_labels, pred_proba = images[i], topk_labels[i], topk_probabilities[i]\n",
        "        # Shortening the labels to better fit in the plot:\n",
        "        pred_labels = [label.split(',')[0][:20] for label in pred_labels]\n",
        "        \n",
        "        grid_spec_i = gridspec.GridSpecFromSubplotSpec(3, 1, subplot_spec=grid_spec[i], \n",
        "                                                       hspace=0.1)\n",
        "        \n",
        "        # Drawing the input image:\n",
        "        ax_img = figure.add_subplot(grid_spec_i[:2])\n",
        "        ax_img.axis('off')\n",
        "        ax_img.imshow(img)\n",
        "        ax_img.autoscale(tight=True)\n",
        "        \n",
        "        # Plotting a bar chart for the predictions:\n",
        "        ax_pred = figure.add_subplot(grid_spec_i[2])\n",
        "        ax_pred.spines['top'].set_visible(False)\n",
        "        ax_pred.spines['right'].set_visible(False)\n",
        "        ax_pred.spines['bottom'].set_visible(False)\n",
        "        ax_pred.spines['left'].set_visible(False)\n",
        "        y_pos = np.arange(len(pred_labels))\n",
        "        ax_pred.barh(y_pos, pred_proba, align='center')\n",
        "        ax_pred.set_yticks(y_pos)\n",
        "        ax_pred.set_yticklabels(pred_labels)\n",
        "        ax_pred.invert_yaxis()\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CcaIuZyFqC2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict_on_batch(val_ds[1])"
      ],
      "metadata": {
        "id": "TRJJAmZ79gKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}