{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPO9jleb2nFbDAHrKolGj3/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/Deep-Learning/blob/main/CNNBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tHKpXQGTfnW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 32,32\n",
        "num_channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "KGrg4k9LWvfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512,activation='tanh'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(128,activation='tanh'))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "5nDEBDrZUBsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "callbacks = [tf.keras.callbacks.TensorBoard('./keras')]\n",
        "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks)"
      ],
      "metadata": {
        "id": "s8zARj-JUosp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic stuff using convulution and pooling"
      ],
      "metadata": {
        "id": "BJ7P45V9ZfmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/d/da/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg"
      ],
      "metadata": {
        "id": "7nP7ZiWQZe8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io        # Package to simply read images"
      ],
      "metadata": {
        "id": "QjlFj1HfZoH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('/content/Epimachus_meyeri_-Papua_New_Guinea_-male-8.jpg').convert('L').resize((600,600))\n"
      ],
      "metadata": {
        "id": "I9CmyeCNZpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D-BIyZzwc6FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "eRZZQ6lxc638"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "5XvxzRG_Zu03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.img_to_array(image)"
      ],
      "metadata": {
        "id": "XmA4jKYhZ4vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.expand_dims(image, axis=0)\n",
        " #tensorflow work on batches "
      ],
      "metadata": {
        "id": "WCT1UERXZ_nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Tensor shape: {}\".format(image.shape))"
      ],
      "metadata": {
        "id": "IAXFCrAiaFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " we define a 3x3 filter (or kernel) commonly used to blur images (Gaussian blur):"
      ],
      "metadata": {
        "id": "QVk-L5mvbC9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[1 / 16, 2 / 16, 1 / 16],\n",
        "                      [2 / 16, 4 / 16, 2 / 16],\n",
        "                      [1 / 16, 2 / 16, 1 / 16]], tf.float32, name=\"gaussian_kernel\")"
      ],
      "metadata": {
        "id": "A_6AVz0ObF6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)\n",
        "kernel.shape"
      ],
      "metadata": {
        "id": "ZtKl-kHQbJF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")"
      ],
      "metadata": {
        "id": "NRRTgkElbQ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurred_res = blurred_image.numpy()\n",
        "# We \"unbatch\" our result by selecting the first (and only) image; we also remove the depth dimension:\n",
        "blurred_res = blurred_res[0, ..., 0]\n",
        "\n",
        "plt.imshow(blurred_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "m0mFMMDQbYlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a kernel for contour detection is used. This kernel is defined as follows:"
      ],
      "metadata": {
        "id": "z_JkplmncUXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = tf.constant([[-1, -1, -1],\n",
        "                      [-1,  8, -1],\n",
        "                      [-1, -1, -1]], tf.float32, name=\"edge_kernel\")\n",
        "kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)"
      ],
      "metadata": {
        "id": "sxvXHwvOcVyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_image = tf.nn.conv2d(image, kernel, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "edge_res = edge_image.numpy()[0, ..., 0]\n",
        "plt.imshow(edge_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "rJltIO6nca6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For max-pooling and average-pooling, the values in each window are aggregated into a single output, applying respectively the max or averaging operation. Once again, we use the low-level TensorFlow API to reproduce the results shown in the chapter:"
      ],
      "metadata": {
        "id": "DqBXmFGgcpP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pooled_image = tf.nn.avg_pool(image, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "avg_res = avg_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(avg_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "kQlWkw87cp8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pooled_image = tf.nn.max_pool(image, ksize=[1, 10, 10, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "max_res = max_pooled_image.numpy()[0, ..., 0]\n",
        "plt.imshow(max_res, cmap=plt.cm.gray)"
      ],
      "metadata": {
        "id": "zhbyW1rKeB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple convulutional network"
      ],
      "metadata": {
        "id": "k8VnnsjceUeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "    def __init__(self,num_classes):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1=tf.keras.layers.Conv2D(20,kernel_size=5,padding=\"same\",activation='relu')\n",
        "        self.conv2=tf.keras.layers.Conv2D(30,kernel_size=5,activation='relu')\n",
        "        self.maxpool=tf.keras.layers.MaxPooling2D(pool_size=2)\n",
        "        self.flatten=tf.keras.layers.Flatten()\n",
        "        self.dense1=tf.keras.layers.Dense(400,activation='relu')\n",
        "        self.dense2=tf.keras.layers.Dense(num_classes,activation='relu')\n",
        "    def call(self,input):\n",
        "        x=self.conv1(input)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.conv2(x)\n",
        "        x=self.maxpool(x)\n",
        "        x=self.flatten(x)\n",
        "        x=self.dense1(x)\n",
        "        x=self.dense2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mrScGKh_fDkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "class LeNet5(Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        :param num_classes:     Number of classes to predict from\n",
        "        \"\"\"\n",
        "        super(LeNet5, self).__init__()\n",
        "        # We instantiate the various layers composing LeNet-5:\n",
        "        # self.conv1 = SimpleConvolutionLayer(6, kernel_size=(5, 5))\n",
        "        # self.conv2 = SimpleConvolutionLayer(16, kernel_size=(5, 5))\n",
        "        # ... or using the existing and (recommended) Conv2D class:\n",
        "        self.conv1 = Conv2D(6, 5, padding='same', activation='relu')\n",
        "        self.conv2 = Conv2D(16, 5, activation='relu')\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu')\n",
        "        self.dense2 = Dense(84, activation='relu')\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Call the layers and perform their operations on the input tensors\n",
        "        :param inputs:  Input tensor\n",
        "        :return:        Output tensor\n",
        "        \"\"\"\n",
        "        x = self.max_pool(self.conv1(inputs))        # 1st block\n",
        "        x = self.max_pool(self.conv2(x))             # 2nd block\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x))) # dense layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "C4mwLn-dh6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "\n",
        "\n",
        "model = LeNet5(10)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]\n",
        "# batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "# model.build(input_shape=batched_input_shape)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "qkflUo1eexlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32, epochs=10, validation_data=(x_test, y_test), \n",
        "                    verbose=1,  # change to `verbose=1` to get a progress bar\n",
        "                                # (we opt for `verbose=2` here to reduce the log size)\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "Z2o6UijJgKaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "aMhiVileeUEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "aeJFM8Qge9W4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}