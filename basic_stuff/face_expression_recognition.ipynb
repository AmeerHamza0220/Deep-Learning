{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc324e4d-902b-469b-869f-cd4a359280cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 11 13:02:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8febd74c-2ab5-4846-96ef-d043d9760591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e1df94-6650-4888-a94f-a17e4f9823ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c0595b-84b0-4ec4-8d19-159bca0694e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/studio-lab-user/.kaggle/kaggle.json'\n",
      "Downloading face-expression-recognition-dataset.zip to /home/studio-lab-user/My notebooks/Some Deep learning\n",
      " 99%|███████████████████████████████████████▌| 119M/121M [00:02<00:00, 58.0MB/s]\n",
      "100%|████████████████████████████████████████| 121M/121M [00:02<00:00, 49.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0681f6a-baa6-4f86-a99b-c118c58ec2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/My notebooks/Some Deep learning/data\n"
     ]
    }
   ],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c383c3f-bf88-4b1e-96dc-5ed1ddcaaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ../face-expression-recognition-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bca5baa3-9465-400b-a20f-a3c82f2eb691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n",
      "Found 7066 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height=96\n",
    "img_width=96\n",
    "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"images/train\", labels='inferred',shuffle=True,image_size=(img_height,\n",
    "    img_width),seed=123,\n",
    " batch_size=128\n",
    "\n",
    ")\n",
    "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"images/validation\", labels='inferred',shuffle=True,image_size=(img_height,\n",
    "    img_width),seed=123,\n",
    " batch_size=128\n",
    "\n",
    ")\n",
    "classes=train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac38c898-5487-444f-bd25-04d0937462a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4c7ec76-a3b6-4ac7-b466-7aaecfea70cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 47, 47, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 20, 20, 64)        36928     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                1638464   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,695,239\n",
      "Trainable params: 1,695,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(img_height,\n",
    "    img_width,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(len(classes),activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99fd7747-c7ff-4275-9be3-f2baf335f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "226/226 [==============================] - 7s 17ms/step - loss: 2.7370 - accuracy: 0.3117 - val_loss: 1.6435 - val_accuracy: 0.3664\n",
      "Epoch 2/10\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 1.5789 - accuracy: 0.3868 - val_loss: 1.5561 - val_accuracy: 0.4022\n",
      "Epoch 3/10\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 1.4890 - accuracy: 0.4249 - val_loss: 1.5199 - val_accuracy: 0.4229\n",
      "Epoch 4/10\n",
      "226/226 [==============================] - 4s 15ms/step - loss: 1.4117 - accuracy: 0.4593 - val_loss: 1.4769 - val_accuracy: 0.4377\n",
      "Epoch 5/10\n",
      "226/226 [==============================] - 5s 20ms/step - loss: 1.3459 - accuracy: 0.4859 - val_loss: 1.4807 - val_accuracy: 0.4462\n",
      "Epoch 6/10\n",
      "226/226 [==============================] - 4s 19ms/step - loss: 1.2769 - accuracy: 0.5167 - val_loss: 1.5220 - val_accuracy: 0.4550\n",
      "Epoch 7/10\n",
      "226/226 [==============================] - 5s 20ms/step - loss: 1.2097 - accuracy: 0.5411 - val_loss: 1.5670 - val_accuracy: 0.4527\n",
      "Epoch 8/10\n",
      "226/226 [==============================] - 4s 15ms/step - loss: 1.1465 - accuracy: 0.5680 - val_loss: 1.6368 - val_accuracy: 0.4614\n",
      "Epoch 9/10\n",
      "226/226 [==============================] - 4s 15ms/step - loss: 1.0758 - accuracy: 0.5969 - val_loss: 1.7030 - val_accuracy: 0.4577\n",
      "Epoch 10/10\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 1.0114 - accuracy: 0.6256 - val_loss: 1.7457 - val_accuracy: 0.4537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe76c379100>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=10\n",
    "model.fit(train_ds,epochs=epochs,validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65d34e7e-7e5b-4b35-8acf-64fd15078771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "9420800/9406464 [==============================] - 0s 0us/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_8   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 7)                 8967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,266,951\n",
      "Trainable params: 8,967\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pretrained model\n",
    "pretrained_model=tf.keras.applications.MobileNetV2(input_shape=(img_height,\n",
    "    img_width,3),include_top=False,weights='imagenet')\n",
    "pretrained_model.trainable=False\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(classes),activation='softmax')\n",
    "])\n",
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f3460bc-a2b3-4e9f-8493-22fbd2d06dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "226/226 [==============================] - 14s 51ms/step - loss: 1.7689 - accuracy: 0.2838 - val_loss: 1.6965 - val_accuracy: 0.3271 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "226/226 [==============================] - 10s 43ms/step - loss: 1.6634 - accuracy: 0.3433 - val_loss: 1.6408 - val_accuracy: 0.3614 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 1.6225 - accuracy: 0.3639 - val_loss: 1.6388 - val_accuracy: 0.3626 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.6015 - accuracy: 0.3755 - val_loss: 1.6101 - val_accuracy: 0.3748 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5835 - accuracy: 0.3858 - val_loss: 1.5958 - val_accuracy: 0.3842 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5708 - accuracy: 0.3911 - val_loss: 1.5901 - val_accuracy: 0.3864 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5562 - accuracy: 0.3998 - val_loss: 1.5904 - val_accuracy: 0.3859 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "225/226 [============================>.] - ETA: 0s - loss: 1.5485 - accuracy: 0.3983\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5483 - accuracy: 0.3984 - val_loss: 1.6085 - val_accuracy: 0.3772 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5326 - accuracy: 0.4087 - val_loss: 1.5964 - val_accuracy: 0.3898 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5269 - accuracy: 0.4124 - val_loss: 1.5789 - val_accuracy: 0.3963 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5216 - accuracy: 0.4130 - val_loss: 1.5807 - val_accuracy: 0.3898 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "225/226 [============================>.] - ETA: 0s - loss: 1.5189 - accuracy: 0.4169\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5189 - accuracy: 0.4169 - val_loss: 1.5797 - val_accuracy: 0.3909 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "226/226 [==============================] - 10s 42ms/step - loss: 1.5109 - accuracy: 0.4187 - val_loss: 1.5753 - val_accuracy: 0.3944 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5091 - accuracy: 0.4205 - val_loss: 1.5716 - val_accuracy: 0.3982 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5061 - accuracy: 0.4211 - val_loss: 1.5696 - val_accuracy: 0.3994 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 1.5051 - accuracy: 0.4222 - val_loss: 1.5716 - val_accuracy: 0.3950 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "225/226 [============================>.] - ETA: 0s - loss: 1.5041 - accuracy: 0.4234\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "226/226 [==============================] - 9s 42ms/step - loss: 1.5039 - accuracy: 0.4235 - val_loss: 1.5707 - val_accuracy: 0.3985 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "226/226 [==============================] - 10s 42ms/step - loss: 1.5003 - accuracy: 0.4242 - val_loss: 1.5705 - val_accuracy: 0.3984 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "226/226 [==============================] - 10s 42ms/step - loss: 1.4988 - accuracy: 0.4254 - val_loss: 1.5686 - val_accuracy: 0.4016 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "226/226 [==============================] - 10s 42ms/step - loss: 1.4983 - accuracy: 0.4274 - val_loss: 1.5691 - val_accuracy: 0.4004 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe75408e310>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1)\n",
    "callbacks=[reduced_lr]\n",
    "epochs=20 \n",
    "\n",
    "model.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a679267-b63f-4f68-b354-53f37af4f955",
   "metadata": {},
   "source": [
    "Same model with trainable set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83992c43-1e9b-4da0-85fc-74d5c3f7d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 8967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,266,951\n",
      "Trainable params: 2,232,839\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pretrained model\n",
    "pretrained_model=tf.keras.applications.MobileNetV2(input_shape=(img_height,\n",
    "    img_width,3),include_top=False,weights='imagenet')\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(classes),activation='softmax')\n",
    "])\n",
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d49c5-13ae-427c-bf54-ad0559a26354",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1)\n",
    "callbacks=[reduced_lr]\n",
    "epochs=20 \n",
    "\n",
    "model.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d7556-9d68-4178-9f9e-a1ae5f381a22",
   "metadata": {},
   "source": [
    "Efficientnet v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e760c3bb-7a0f-47e5-9680-e6f5cb730326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24281088/24274472 [==============================] - 0s 0us/step\n",
      "24289280/24274472 [==============================] - 0s 0us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 3, 3, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d_11  (None, 1280)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 7)                 8967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,928,279\n",
      "Trainable params: 8,967\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model=tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=(img_height,img_width,3),include_top=False,weights='imagenet')\n",
    "pretrained_model.trainable=False\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(classes),activation='softmax')\n",
    "])\n",
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f70f13-6922-4659-ac94-6768df0246ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db9d54d0-41db-43d1-b774-1f1067fb5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "226/226 [==============================] - 19s 60ms/step - loss: 1.5188 - accuracy: 0.4169 - val_loss: 1.3995 - val_accuracy: 0.4710 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.3594 - accuracy: 0.4863 - val_loss: 1.3406 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.3078 - accuracy: 0.5074 - val_loss: 1.3167 - val_accuracy: 0.5003 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.2776 - accuracy: 0.5190 - val_loss: 1.3008 - val_accuracy: 0.5083 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.2552 - accuracy: 0.5299 - val_loss: 1.2878 - val_accuracy: 0.5143 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.2382 - accuracy: 0.5398 - val_loss: 1.2810 - val_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "226/226 [==============================] - 12s 53ms/step - loss: 1.2244 - accuracy: 0.5434 - val_loss: 1.2748 - val_accuracy: 0.5187 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.2112 - accuracy: 0.5512 - val_loss: 1.2746 - val_accuracy: 0.5190 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.2010 - accuracy: 0.5536 - val_loss: 1.2692 - val_accuracy: 0.5214 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1925 - accuracy: 0.5588 - val_loss: 1.2697 - val_accuracy: 0.5226 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1855 - accuracy: 0.5599 - val_loss: 1.2665 - val_accuracy: 0.5245 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1785 - accuracy: 0.5647 - val_loss: 1.2632 - val_accuracy: 0.5256 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1708 - accuracy: 0.5673 - val_loss: 1.2622 - val_accuracy: 0.5252 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1665 - accuracy: 0.5677 - val_loss: 1.2625 - val_accuracy: 0.5277 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "226/226 [==============================] - 12s 53ms/step - loss: 1.1601 - accuracy: 0.5726 - val_loss: 1.2626 - val_accuracy: 0.5269 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "226/226 [==============================] - 12s 52ms/step - loss: 1.1577 - accuracy: 0.5725 - val_loss: 1.2637 - val_accuracy: 0.5293 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "226/226 [==============================] - 12s 53ms/step - loss: 1.1535 - accuracy: 0.5717 - val_loss: 1.2645 - val_accuracy: 0.5282 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "225/226 [============================>.] - ETA: 0s - loss: 1.1491 - accuracy: 0.5752\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "226/226 [==============================] - 12s 54ms/step - loss: 1.1489 - accuracy: 0.5752 - val_loss: 1.2639 - val_accuracy: 0.5286 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "226/226 [==============================] - 12s 54ms/step - loss: 1.1376 - accuracy: 0.5811 - val_loss: 1.2609 - val_accuracy: 0.5324 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "226/226 [==============================] - 12s 54ms/step - loss: 1.1350 - accuracy: 0.5818 - val_loss: 1.2612 - val_accuracy: 0.5307 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7544c5d60>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1)\n",
    "callbacks=[reduced_lr]\n",
    "epochs=20 \n",
    "\n",
    "model.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed005921-aaab-411c-a4cd-15ac8c269819",
   "metadata": {},
   "source": [
    "Trying EfficientNetV2B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3c2c7fc-2e6e-464a-92f1-d0c50fad6200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n",
      "35840000/35839040 [==============================] - 1s 0us/step\n",
      "35848192/35839040 [==============================] - 1s 0us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b2 (Function  (None, 3, 3, 1408)       8769374   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d_13  (None, 1408)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 7)                 9863      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,779,237\n",
      "Trainable params: 9,863\n",
      "Non-trainable params: 8,769,374\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model=tf.keras.applications.efficientnet_v2.EfficientNetV2B2(input_shape=(img_height,img_width,3),include_top=False,weights='imagenet')\n",
    "pretrained_model.trainable=False\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(classes),activation='softmax')\n",
    "])\n",
    "learning_rate=0.001\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f46da3d8-4599-45fb-a62e-fa69a623b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "226/226 [==============================] - 25s 80ms/step - loss: 1.5378 - accuracy: 0.4103 - val_loss: 1.4243 - val_accuracy: 0.4612 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.3789 - accuracy: 0.4819 - val_loss: 1.3610 - val_accuracy: 0.4861 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.3244 - accuracy: 0.5046 - val_loss: 1.3297 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2900 - accuracy: 0.5198 - val_loss: 1.3135 - val_accuracy: 0.5034 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2669 - accuracy: 0.5283 - val_loss: 1.3015 - val_accuracy: 0.5088 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2484 - accuracy: 0.5362 - val_loss: 1.2955 - val_accuracy: 0.5133 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.2336 - accuracy: 0.5422 - val_loss: 1.2857 - val_accuracy: 0.5161 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2198 - accuracy: 0.5489 - val_loss: 1.2795 - val_accuracy: 0.5198 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2099 - accuracy: 0.5509 - val_loss: 1.2756 - val_accuracy: 0.5236 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.2001 - accuracy: 0.5557 - val_loss: 1.2702 - val_accuracy: 0.5256 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.1908 - accuracy: 0.5591 - val_loss: 1.2669 - val_accuracy: 0.5258 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1837 - accuracy: 0.5622 - val_loss: 1.2658 - val_accuracy: 0.5282 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1775 - accuracy: 0.5652 - val_loss: 1.2669 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1707 - accuracy: 0.5664 - val_loss: 1.2638 - val_accuracy: 0.5289 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1648 - accuracy: 0.5708 - val_loss: 1.2643 - val_accuracy: 0.5286 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1597 - accuracy: 0.5705 - val_loss: 1.2639 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1554 - accuracy: 0.5750 - val_loss: 1.2644 - val_accuracy: 0.5267 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "226/226 [==============================] - 16s 71ms/step - loss: 1.1511 - accuracy: 0.5736 - val_loss: 1.2630 - val_accuracy: 0.5303 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1462 - accuracy: 0.5766 - val_loss: 1.2605 - val_accuracy: 0.5290 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "226/226 [==============================] - 16s 72ms/step - loss: 1.1427 - accuracy: 0.5780 - val_loss: 1.2606 - val_accuracy: 0.5321 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3940593d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1)\n",
    "callbacks=[reduced_lr]\n",
    "epochs=20 \n",
    "\n",
    "model.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9985f16-cd65-44e7-aaab-acc71f531104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6b99f-f070-45cc-9685-e280097a920b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pt:Python",
   "language": "python",
   "name": "conda-env-dl_pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
